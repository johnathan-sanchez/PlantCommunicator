{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217fbb36",
   "metadata": {},
   "source": [
    "# Imageomics Bioclip-demo \n",
    "BioClip is a model using CLIP architecture as a vison model for general organismal biology. Trained on TreeOfLife-10M dataset. BioClip includes a understanding on the hierarchical structure that relates species across the tree of life.\n",
    "\n",
    "For the purpose of Plant Commnicator I will utilize this model to identify common houseplants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea262d9",
   "metadata": {},
   "source": [
    "## 1. Load the Model and Tokenizer\n",
    "To begin, we will install the necessary libraries for the model and houseplant identification task. We will load a pre-trained model and its corresponding tokenizer using the Hugging Face Transformers library. The tokenizer is responsible for converting the input text into a format that the model can understand, while the model is used to perform the actual predictions or classifications. We will specify the model name, load the tokenizer, and then load the model. This process ensures that we have all the necessary components to perform text processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce366ad4-1d48-4f7e-b0b6-0a15015331f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:imageomics/bioclip')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:imageomics/bioclip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfb993",
   "metadata": {},
   "source": [
    "## 2. Tokenize Common houseplant names\n",
    "\n",
    "We will input a file that includes a list of common houseplant names included in the BioClip model. This will be used to classify and tokenize the ext using the model's tokenizer. This prepares the items for input into the model by converting them into a format the model can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3245fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Plant Names: tensor([[49406,  8798,  3912,  ...,     0,     0,     0],\n",
      "        [49406,  3021, 10647,  ...,     0,     0,     0],\n",
      "        [49406,   628, 41965,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406,  3329,   539,  ...,     0,     0,     0],\n",
      "        [49406,  9287,  4108,  ...,     0,     0,     0],\n",
      "        [49406,  1192,   917,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"./houseplants.csv\")  # Ensure the path is correct\n",
    "\n",
    "# Extract plant names (common or species names depending on the column names)\n",
    "plant_names = df[\"Common Name\"].tolist()\n",
    "\n",
    "tokenized_names = tokenizer(plant_names)\n",
    "\n",
    "print(\"Tokenized Plant Names:\", tokenized_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3dde969-4052-46d3-b61a-0b8d2e46d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"./RubberTreePlant.webp\"\n",
    "image = preprocess_val(Image.open(image_path)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9309871e-d6a2-472c-a237-79856796ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Plant: Pothos\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "image = image.to(device)\n",
    "\n",
    "# Get text embeddings\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(tokenized_names)\n",
    "\n",
    "# Compute similarity\n",
    "similarities = torch.cosine_similarity(image_features, text_features)\n",
    "predicted_index = similarities.argmax().item()\n",
    "predicted_plant = plant_names[predicted_index]\n",
    "\n",
    "print(\"Predicted Plant:\", predicted_plant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
